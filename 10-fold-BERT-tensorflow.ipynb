{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a1f3c84",
      "metadata": {
        "id": "9a1f3c84"
      },
      "outputs": [],
      "source": [
        "train_dir = 'train_data_after_washing.csv'\n",
        "test_dir = 'test_data_after_washing.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb802c3",
      "metadata": {
        "id": "0bb802c3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from tensorflow.keras.models import Model\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score, cohen_kappa_score, roc_curve, auc, make_scorer, accuracy_score, f1_score\n",
        "tf.get_logger().setLevel('ERROR') # return ERROR messages, ignore others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a97ccc7e",
      "metadata": {
        "id": "a97ccc7e"
      },
      "outputs": [],
      "source": [
        "#one hot\n",
        "def encode_one_hot(ori_dataframe):\n",
        "    dummies = pd.get_dummies(ori_dataframe)\n",
        "    res = pd.concat([ori_dataframe, dummies], axis=1)\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3918b0af",
      "metadata": {
        "id": "3918b0af"
      },
      "outputs": [],
      "source": [
        "#load data\n",
        "data = pd.read_csv(train_dir)\n",
        "data = pd.DataFrame(data)\n",
        "test_data = pd.read_csv(test_dir)\n",
        "test_data = pd.DataFrame(test_data)\n",
        "train_data = pd.DataFrame()\n",
        "val_data = pd.DataFrame()\n",
        "data = data[[\"review\",\"rating\"]]\n",
        "test_data = test_data[[\"review\",\"rating\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26b6aac5",
      "metadata": {
        "id": "26b6aac5"
      },
      "outputs": [],
      "source": [
        "data['labels'] = data['rating'].map({1 : 0,\n",
        "                                     2 : 0,\n",
        "                                     3 : 0,\n",
        "                                     4 : 0,\n",
        "                                     5 : 1,\n",
        "                                     6 : 1,\n",
        "                                     7 : 1,\n",
        "                                     8 : 1,\n",
        "                                     9 : 2,\n",
        "                                     10 : 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3ee1a2c",
      "metadata": {
        "id": "d3ee1a2c"
      },
      "outputs": [],
      "source": [
        "test_data['labels'] = test_data['rating'].map({1 : 0,\n",
        "                                               2 : 0,\n",
        "                                               3 : 0,\n",
        "                                               4 : 0,\n",
        "                                               5 : 1,\n",
        "                                               6 : 1,\n",
        "                                               7 : 1,\n",
        "                                               8 : 1,\n",
        "                                               9 : 2,\n",
        "                                               10 : 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7aabf2e",
      "metadata": {
        "id": "c7aabf2e"
      },
      "outputs": [],
      "source": [
        "#extract data\n",
        "data = data[[\"review\",\"labels\"]]\n",
        "y = data[\"labels\"].to_numpy()\n",
        "Y = data[\"labels\"]\n",
        "#data = encode_one_hot(data)\n",
        "test_data = test_data[[\"review\",\"labels\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cd08b44",
      "metadata": {
        "id": "7cd08b44"
      },
      "outputs": [],
      "source": [
        "X = data[\"review\"].to_numpy()\n",
        "#Y = data[[0,1,2]].to_numpy\n",
        "test_X = test_data[\"review\"].to_numpy()\n",
        "test_y = test_data[\"labels\"].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43d159e8",
      "metadata": {
        "id": "43d159e8"
      },
      "outputs": [],
      "source": [
        "def build_classifier_model(tfhub_handle_encoder,tfhub_handle_preprocess):\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "    encoder_inputs = preprocessing_layer(text_input)\n",
        "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net = outputs['pooled_output']\n",
        "    net = tf.keras.layers.Dropout(0.1)(net)\n",
        "    net = tf.keras.layers.Dense(3, activation='softmax', name='classifier')(net)\n",
        "    return tf.keras.Model(text_input, net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7d45a60",
      "metadata": {
        "id": "f7d45a60"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def model_training(x_train, y_train, x_val, y_val, times):\n",
        "    times = str(times)\n",
        "    tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/albert_en_base/2'\n",
        "    tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/albert_en_preprocess/3'\n",
        "    bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
        "    bert_model = hub.KerasLayer(tfhub_handle_encoder)\n",
        "    classifier_model = build_classifier_model(tfhub_handle_encoder, tfhub_handle_preprocess)\n",
        "    classifier_model.summary()\n",
        "    epochs = 150\n",
        "    steps_per_epoch = 0\n",
        "    for _ in x_train:\n",
        "        steps_per_epoch = steps_per_epoch + 1\n",
        "    num_train_steps = steps_per_epoch/24 * epochs\n",
        "    num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "    init_lr = 3e-6\n",
        "    optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                              num_train_steps=num_train_steps,\n",
        "                                              num_warmup_steps=num_warmup_steps,\n",
        "                                              optimizer_type='adamw')\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "    classifier_model.compile(optimizer=optimizer,\n",
        "                             loss=loss,\n",
        "                             metrics=[\"accuracy\", tf.keras.metrics.Recall(name='recall')])\n",
        "    file_name='TWB_Cross' + times + '_2_121_1.25'\n",
        "    checkpoint_path = 'C:/Users/ROG/OneDrive/桌面/FYP/Model/'+ file_name + '/ckpt/cp.ckpt'\n",
        "    cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "    csv_callback = tf.keras.callbacks.CSVLogger(\n",
        "    'C:/Users/ROG/OneDrive/桌面/FYP/Model/'+ file_name + '/record.csv', separator=',', append=False\n",
        "    )\n",
        "    t0 = time.time()\n",
        "    print(f'Training model with {tfhub_handle_encoder}')\n",
        "    print(f'Training model with {tfhub_handle_encoder}')\n",
        "    history = classifier_model.fit(x=x_train,\n",
        "                                   y=y_train,\n",
        "                                   validation_data=(x_val,y_val),\n",
        "                                   epochs=150,\n",
        "                                   batch_size=24,\n",
        "                                   callbacks=[cp_callback,csv_callback])\n",
        "    t1 = time.time()\n",
        "    time_train = t1-t0\n",
        "    return (classifier_model,time_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ce1dfc8",
      "metadata": {
        "id": "6ce1dfc8"
      },
      "outputs": [],
      "source": [
        "def graded_precision(y_true, y_pred, weights):\n",
        "    precision_0 = precision_score(y_true, y_pred, labels=[0], average='macro')\n",
        "    precision_1 = precision_score(y_true, y_pred, labels=[1], average='macro')\n",
        "    precision_2 = precision_score(y_true, y_pred, labels=[2], average='macro')\n",
        "    gp = ( weights[0] * precision_0 + weights[1] * precision_1 + weights[2] * precision_2 ) / ( weights[0] + weights[1] + weights[2] )\n",
        "    return gp\n",
        "def graded_recall(y_true, y_pred, weights):\n",
        "    recall_0 = recall_score(y_true, y_pred, labels=[0], average='macro')\n",
        "    recall_1 = recall_score(y_true, y_pred, labels=[1], average='macro')\n",
        "    recall_2 = recall_score(y_true, y_pred, labels=[2], average='macro')\n",
        "    gr = ( weights[0] * recall_0 + weights[1] * recall_1 + weights[2] * recall_2 ) / ( weights[0] + weights[1] + weights[2] )\n",
        "    return gr\n",
        "def graded_f1(precision, recall):\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f21b071e",
      "metadata": {
        "id": "f21b071e"
      },
      "outputs": [],
      "source": [
        "def model_testing(model, X, y, times,val):\n",
        "    times = str(times)\n",
        "    #generate y_true and prediction results\n",
        "    y_true = y\n",
        "    if val == True:\n",
        "        y_true = np.argmax(y, axis=1)\n",
        "    pred = np.argmax(model.predict(X),axis=1)\n",
        "\n",
        "    #different metrics\n",
        "    acc = accuracy_score(y_true, pred)\n",
        "    weights = [2, 1, 1]\n",
        "    prec = graded_precision(y_true, pred, weights)\n",
        "    rec = graded_recall(y_true, pred, weights)\n",
        "    f1 = graded_f1(prec, rec)\n",
        "    kappa = cohen_kappa_score(y_true, pred)\n",
        "\n",
        "    #CM\n",
        "    if val == False:\n",
        "        con_mat = confusion_matrix(y, pred)\n",
        "        con_mat_norm = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]     # 归一化\n",
        "        con_mat_norm = np.around(con_mat_norm, decimals=2)\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        sns.heatmap(con_mat_norm, annot=True, cmap='Blues')\n",
        "        plt.ylim(0, 3)\n",
        "        plt.xlabel('Predicted labels')\n",
        "        plt.ylabel('True labels')\n",
        "        #save CM\n",
        "        file_name='TWB_Cross' + times + '_2_121_1.25'\n",
        "        plt.savefig(fname=''+ file_name + '/CM.png', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    return (acc, prec, rec, f1, kappa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "408cd7cd",
      "metadata": {
        "scrolled": true,
        "id": "408cd7cd"
      },
      "outputs": [],
      "source": [
        "#10-fold\n",
        "skf = StratifiedKFold(n_splits=10)\n",
        "val_acc = []\n",
        "val_gp = []\n",
        "val_gr = []\n",
        "val_f1 = []\n",
        "val_kp = []\n",
        "tes_acc = []\n",
        "tes_gp = []\n",
        "tes_gr = []\n",
        "tes_f1 = []\n",
        "tes_kp = []\n",
        "train_time = []\n",
        "times = 0\n",
        "for train_index, val_index in skf.split(X, y):\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    y_train, y_val = Y[train_index], Y[val_index]\n",
        "    y_train = encode_one_hot(y_train)\n",
        "    y_val = encode_one_hot(y_val)\n",
        "    y_train = y_train[[0,1,2]].to_numpy()\n",
        "    y_val = y_val[[0,1,2]].to_numpy()\n",
        "    model,time_train = model_training(X_train, y_train, X_val, y_val, times)\n",
        "    train_time.append(time_train)\n",
        "    val = True\n",
        "    acc, prec, rec, f1, kappa = model_testing(model, X_val, y_val, times, val)\n",
        "    val_acc.append(acc)\n",
        "    val_gp.append(prec)\n",
        "    val_gr.append(rec)\n",
        "    val_f1.append(f1)\n",
        "    val_kp.append(kappa)\n",
        "    val = False\n",
        "    acc, prec, rec, f1, kappa = model_testing(model, test_X, test_y, times, val)\n",
        "    tes_acc.append(acc)\n",
        "    tes_gp.append(prec)\n",
        "    tes_gr.append(rec)\n",
        "    tes_f1.append(f1)\n",
        "    tes_kp.append(kappa)\n",
        "    times = times + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a49e41a4",
      "metadata": {
        "id": "a49e41a4"
      },
      "outputs": [],
      "source": [
        "matrics_list = [val_acc, val_gp, val_gr, val_f1, val_kp, tes_acc, tes_gp, tes_gr, tes_f1, tes_kp, train_time]\n",
        "avg_results = []\n",
        "for matric in matrics_list:\n",
        "    total = 0\n",
        "    for item in matric:\n",
        "        total = total + item\n",
        "    avg_results.append(total/len(matric))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a73b107",
      "metadata": {
        "id": "9a73b107"
      },
      "outputs": [],
      "source": [
        "avg_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af2cabfe",
      "metadata": {
        "id": "af2cabfe"
      },
      "outputs": [],
      "source": [
        "with open(\"BERT_new_crossloss.txt\", \"w\") as f:\n",
        "    f.write(\"val_acc: \")\n",
        "    for item in val_acc:\n",
        "        f.write(str(item))\n",
        "        if val_acc.index(item) == len(val_acc) - 1: # Check if last item\n",
        "            f.write(';')\n",
        "        else:\n",
        "            f.write(', ')\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.write(\"val_gp: \")\n",
        "    for item in val_gp:\n",
        "        f.write(str(item))\n",
        "        if val_gp.index(item) == len(val_acc) - 1: # Check if last item\n",
        "            f.write(';')\n",
        "        else:\n",
        "            f.write(', ')\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.write(\"val_gr: \")\n",
        "    for item in val_gr:\n",
        "        f.write(str(item))\n",
        "        if val_gr.index(item) == len(val_acc) - 1: # Check if last item\n",
        "            f.write(';')\n",
        "        else:\n",
        "            f.write(', ')\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.write(\"val_f1: \")\n",
        "    for item in val_f1:\n",
        "        f.write(str(item))\n",
        "        if val_f1.index(item) == len(val_acc) - 1: # Check if last item\n",
        "            f.write(';')\n",
        "        else:\n",
        "            f.write(', ')\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.write(\"val_kp: \")\n",
        "    for item in val_kp:\n",
        "        f.write(str(item))\n",
        "        if val_kp.index(item) == len(val_acc) - 1: # Check if last item\n",
        "            f.write(';')\n",
        "        else:\n",
        "            f.write(', ')\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.write(\"tes_acc: \")\n",
        "    for item in tes_acc:\n",
        "        f.write(str(item))\n",
        "        if tes_acc.index(item) == len(val_acc) - 1: # Check if last item\n",
        "            f.write(';')\n",
        "        else:\n",
        "            f.write(', ')\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.write(\"tes_gp: \")\n",
        "    for item in tes_gp:\n",
        "        f.write(str(item))\n",
        "        if tes_gp.index(item) == len(val_acc) - 1: # Check if last item\n",
        "            f.write(';')\n",
        "        else:\n",
        "            f.write(', ')\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.write(\"tes_gr: \")\n",
        "    for item in tes_gr:\n",
        "        f.write(str(item))\n",
        "        if tes_gr.index(item) == len(val_acc) - 1: # Check if last item\n",
        "            f.write(';')\n",
        "        else:\n",
        "            f.write(', ')\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.write(\"tes_f1: \")\n",
        "    for item in tes_f1:\n",
        "        f.write(str(item))\n",
        "        if tes_f1.index(item) == len(val_acc) - 1: # Check if last item\n",
        "            f.write(';')\n",
        "        else:\n",
        "            f.write(', ')\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.write(\"tes_kp: \")\n",
        "    for item in tes_kp:\n",
        "        f.write(str(item))\n",
        "        if tes_kp.index(item) == len(val_acc) - 1: # Check if last item\n",
        "            f.write(';')\n",
        "        else:\n",
        "            f.write(', ')\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.write(\"train_time: \")\n",
        "    for item in train_time:\n",
        "        f.write(str(item))\n",
        "        if train_time.index(item) == len(train_time) - 1: # Check if last item\n",
        "            f.write(';')\n",
        "        else:\n",
        "            f.write(', ')\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.write(\"average_results: \")\n",
        "    for item in avg_results:\n",
        "        f.write(str(item))\n",
        "        if avg_results.index(item) == len(avg_results) - 1: # Check if last item\n",
        "            f.write(';')\n",
        "        else:\n",
        "            f.write(', ')\n",
        "    f.write(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tensorflow-gpu",
      "language": "python",
      "name": "tensorflow-gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}